<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Saeed  Ghorbani</title>
<meta name="description" content="Saeed Ghorbani, PhD student, Department of Electrical Engineering and Computer Science, York University
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="row ml-1 ml-sm-0">
          <span class="contact-icon text-center">
  <a href="mailto:%73%61%65%65%64 %61%74 %65%65%63%73 %64%6F%74 %79%6F%72%6B%75 %64%6F%74 %63%61"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=JFRY_g8AAAAJ&hl# your Google Scholar ID" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  
  <a href="https://github.com/saeed1262# your GitHub user name" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  <a href="https://twitter.com/SaGhorbani# your Twitter handle" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
</span>

        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Saeed</span>   <span class="font-weight-bold">Ghorbani</span>
    </h1>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/profile_pic.jpeg">
      
      
        <div class="address">
          <p>Ph.D. Student</p> <p>Department of Electrical Engineering and Computer Science</p> <p>York University</p> <p>Toronto, Canada</p>

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am a third-year Ph.D. student in Electrical Engineering and Computer Science at York University, Toronto, advised by <a href="https://www.biomotionlab.ca/niko-troje/">Dr. Niko Troje</a>. I am also a <a href="https://vista.info.yorku.ca/">VISTA</a> and <a href="http://www.cvr.yorku.ca/">CVR</a> trainee. My research interests are machine learning, computer vision, computer graphics, and computer animation. My current research focus is on leveraging novel deep probabilistic models for realistic human motion modelling.</p>

    </div>

    
      <div class="news">
  <h2>Highlights</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Apr 8, 2021</th>
          <td>
            
              Our paper <a href="saeed1262.github.io/assets/pdf/Applied_Intelligence_2020.pdf">“Estimating Pose from Pressure Data for Smart Beds withDeep Image-based Pose Estimators”</a> was accepted at <a href="https://www.springer.com/journal/10489">Journal of Applied Intelligence, Springer</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 27, 2021</th>
          <td>
            
              Our paper <a href="https://arxiv.org/pdf/1908.08919.pdf">“In-bed Pressure-based Pose Estimation using Image Space Representation Learning”</a> was accepted at <a href="https://2021.ieeeicassp.org/">ICASSP2021</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 10, 2020</th>
          <td>
            
              Our paper <a href="https://arxiv.org/abs/2010.09084">“Gait Recognition using Multi-Scale Partial Representation Transformation with Capsules”</a> was accepted at <a href="https://www.micc.unifi.it/icpr2020/">ICPR2020</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 1, 2020</th>
          <td>
            
              Our <a href="https://saeed1262.github.io/projects/motionModel/">new paper</a> on Motion Modelling is now published at Computer Graphics Forum. Watch the <a href="https://www.youtube.com/watch?v=jw0_aBPROGA&amp;t=93s">short</a> and <a href="https://www.youtube.com/watch?v=r9F74LcGC0A&amp;t=689s">long</a> presentations.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 6, 2020</th>
          <td>
            
              <strong>MoVi</strong>: We just published a BIG new data set of human motion data. 9h mocap + 17h calibrated video + 7h of IMU + MoSh reconstructed body shape. Check the <a href="http://biomotionlab.ca/movi/">website</a>

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected Publications</h2>
  <ol class="bibliography"><li><div class="row">
    <div class="col-sm-2 abbr">
         
        <abbr class="badge">CGF</abbr>
         
        <span class="award badge"></span>
    </div>

    <div id="ghorbani2020b" class="col-sm-8">
        
        <div class="title">Probabilistic Character Motion Synthesis using a Hierarchical Deep Latent Variable Model</div>
        <div class="author">
             
             
            <em>Ghorbani, Saeed</em>,     
              
            <a href="http://www.cse.yorku.ca/~calden/" target="_blank"
                >Wloka, Calden</a
            >,      
              
            <a href="http://alietemad.com/" target="_blank"
                >Etemad, Ali</a
            >,      
              
            <a href="https://mbrubake.github.io/" target="_blank"
                >Brubaker, Marcus A.</a
            >,      
               and
            <a href="https://www.biomotionlab.ca/niko-troje/" target="_blank"
                >Troje, Nikolaus F.</a
            >
                
        </div>

        <div class="periodical">
            
            <em>Computer Graphics Forum (Symposium on Computer Aanimation)</em>
              2020 
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                
            <a
                href="/assets/pdf/GhorbaniSCA2020.pdf"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >PDF</a
            >
                   
            <a
                href="https://saeed1262.github.io/projects/motionModel/"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >Website</a
            >
             
            <a
                href="https://www.youtube.com/watch?v=r9F74LcGC0A"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >Talk</a
            >
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>We present a probabilistic framework to generate character animations based on weak control signals, such that the synthesized motions are realistic while retaining the stochastic nature of human movement. The proposed architecture, which is designed as a hierarchical recurrent model, maps each sub-sequence of motions into a stochastic latent code using a variational autoencoder extended over the temporal domain. We also propose an objective function which respects the impact of each joint on the pose and compares the joint angles based on angular distance. We use two novel quantitative protocols and human qualitative assessment to demonstrate the ability of our model to generate convincing and diverse periodic and non-periodic motion sequences without the need for strong control signals.</p>
        </div>
        
    </div>
</div>
</li>
<li><div class="row">
    <div class="col-sm-2 abbr">
         
        <abbr class="badge">arXiv</abbr>
         
        <span class="award badge"></span>
    </div>

    <div id="ghorbani2020movi" class="col-sm-8">
        
        <div class="title">MoVi: A Large Multipurpose Motion and Video Dataset</div>
        <div class="author">
             
             
            <em>Ghorbani, Saeed</em>,     
               Mahdaviani, Kimia,      
               Thaler, Anne,      
              
            <a href="http://koerding.com/" target="_blank"
                >Kording, Konrad</a
            >,      
               Cook, Douglas James,      
              
            <a href="http://www.compneurosci.com/people.html" target="_blank"
                >Blohm, Gunnar</a
            >,      
               and
            <a href="https://www.biomotionlab.ca/niko-troje/" target="_blank"
                >Troje, Nikolaus F.</a
            >
                
        </div>

        <div class="periodical">
            
            <em>arXiv:2003.01888</em>
              2020 
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                
            <a
                href="https://arxiv.org/pdf/2003.01888.pdf"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >PDF</a
            >
                
            <a
                href="https://github.com/saeed1262/MoVi-Toolbox"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >Code</a
            >
               
            <a
                href="https://www.biomotionlab.ca/movi/"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >Website</a
            >
             
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Human movements are both an area of intense study and the basis of many applications such as character animation. For many applications, it is crucial to identify movements from videos or analyze datasets of movements. Here we introduce a new human Motion and Video dataset MoVi, which we make available publicly. It contains 60 female and 30 male actors performing a collection of 20 predefined everyday actions and sports movements, and one self-chosen movement. In five capture rounds, the same actors and movements were recorded using different hardware systems, including an optical motion capture system, video cameras, and inertial measurement units (IMU). For some of the capture rounds, the actors were recorded when wearing natural clothing, for the other rounds they wore minimal clothing. In total, our dataset contains 9 hours of motion capture data, 17 hours of video data from 4 different points of view (including one hand-held camera), and 6.6 hours of IMU data. In this paper, we describe how the dataset was collected and post-processed; We present state-of-the-art estimates of skeletal motions and full-body shape deformations associated with skeletal motion. We discuss examples for potential studies this dataset could enable.</p>
        </div>
        
    </div>
</div>
</li>
<li><div class="row">
    <div class="col-sm-2 abbr">
         
        <abbr class="badge">CGI</abbr>
         
        <span class="award badge">Best Paper Award</span>
    </div>

    <div id="ghorbani2019auto" class="col-sm-8">
        
        <div class="title">Auto-labelling of markers in optical motion capture by permutation learning</div>
        <div class="author">
             
             
            <em>Ghorbani, Saeed</em>,     
              
            <a href="http://alietemad.com/" target="_blank"
                >Etemad, Ali</a
            >,      
               and
            <a href="https://www.biomotionlab.ca/niko-troje/" target="_blank"
                >Troje, Nikolaus F</a
            >
                
        </div>

        <div class="periodical">
            
            <em>In Computer Graphics International</em>
              2019 
        </div>
        

        <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                
            <a
                href="https://arxiv.org/pdf/1907.13580.pdf"
                class="btn btn-sm z-depth-0"
                role="button"
                target="_blank"
                >PDF</a
            >
                    
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Optical marker-based motion capture is a vital tool in applications such as motion and behavioural analysis, animation, and biomechanics. Labelling, that is, assigning optical markers to the pre-defined positions on the body is a time consuming and labour intensive postprocessing part of current motion capture pipelines. The problem can be considered as a ranking process in which markers shuffled by an unknown permutation matrix are sorted to recover the correct order. In this paper, we present a framework for automatic marker labelling which first estimates a permutation matrix for each individual frame using a differentiable permutation learning model and then utilizes temporal consistency to identify and correct remaining labelling errors. Experiments conducted on the test data show the effectiveness of our framework.</p>
        </div>
        
    </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%73%61%65%65%64 %61%74 %65%65%63%73 %64%6F%74 %79%6F%72%6B%75 %64%6F%74 %63%61"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=JFRY_g8AAAAJ&hl# your Google Scholar ID" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  
  <a href="https://github.com/saeed1262# your GitHub user name" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  <a href="https://twitter.com/SaGhorbani# your Twitter handle" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
  
  
  
  
</span>

      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Saeed  Ghorbani.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: April 09, 2021.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-179482637-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-179482637-1');
</script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>



</html>
